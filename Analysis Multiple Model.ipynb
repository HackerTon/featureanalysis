{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816d00ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2dae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# [w, h, c], 448, 448, 3\n",
    "def decode_crop(image, label):\n",
    "    image = image[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "    label = label[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for index in range(4 * 8):\n",
    "        x, y = index // 8, index % 8\n",
    "        img_array.append(image[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "        label_array.append(label[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((img_array, label_array))\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append((label[:, :, 0] == 0) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0))\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 64) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 0) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 0) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 192) & (label[:, :, 1] == 0) & (label[:, :, 2] == 192)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 64) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, istrain=True, maximage=False):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    if istrain:\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Images/*.png\"\n",
    "        )\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Labels/*.png\"\n",
    "        )\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "    else:\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Images/*.png\"\n",
    "        )\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Labels/*.png\"\n",
    "        )\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.cache()\n",
    "    if istrain:\n",
    "        ds = ds.shuffle(6400, SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(get_image_decode, AUTOTUNE)\n",
    "\n",
    "    if not maximage:\n",
    "        ds = ds.flat_map(decode_crop)\n",
    "\n",
    "    ds = ds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # batch and prefetch\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    if istrain:\n",
    "        ds = ds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ef5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=False)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "\n",
    "        return m_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebebd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_3 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_4 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(4, 4),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv1_o, conv2_o, conv3_o, conv4_o = self.backbone(images, training=False)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv4_o) + conv3_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv2_o\n",
    "        fcn_4x = self.upscale2x_3(fcn_8x) + conv1_o\n",
    "        final_output = self.upscale2x_4(fcn_4x)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcea6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescalingUnet(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(RescalingUnet, self).__init__()\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return ((inputs * (1 / 255.0)) - self.mean) / self.std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325aa813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path_name):\n",
    "    \"\"\"\n",
    "    return None if no weight loaded\n",
    "    \"\"\"\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "    ckptmg = tf.train.CheckpointManager(ckpt, path_name, 5)\n",
    "\n",
    "    if ckptmg.latest_checkpoint is None:\n",
    "        return None\n",
    "    ckpt.restore(ckptmg.latest_checkpoint).expect_partial()\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76060da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model_unetfpn(mode=\"multi\", n_classes=8):\n",
    "    model_unet = sm.Unet(\n",
    "        backbone_name=\"efficientnetb0\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        encoder_freeze=False,\n",
    "        classes=n_classes,\n",
    "        decoder_use_batchnorm=False,\n",
    "    )\n",
    "    model_fpn = FCN(n_classes)\n",
    "\n",
    "    conv1x1 = keras.layers.Conv2D(n_classes, 1, padding=\"same\", activation=\"softmax\")\n",
    "    rescale_layer = RescalingUnet()\n",
    "    input_layer = keras.layers.Input([None, None, 3])\n",
    "\n",
    "    output_model_fcn = model_unet(rescale_layer(input_layer))\n",
    "    output_model_fpn = model_fpn(input_layer)\n",
    "    output = output_model_fcn * output_model_fpn\n",
    "    output_final = conv1x1(output)\n",
    "\n",
    "    return keras.Model([input_layer], [output_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de64f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model_fcnfpn(mode=\"multi\", n_classes=8):\n",
    "    model_fcn = FCN_ORIG(n_classes)\n",
    "    model_fpn = FCN(n_classes)\n",
    "\n",
    "    # if load_model(model_fcn, \"trained_model/fcn8s\") == None:\n",
    "    #     print(\"failed to load fcn8s\")\n",
    "    #     return\n",
    "\n",
    "    # if load_model(model_fpn, \"trained_model/fpn\") == None:\n",
    "    #     print(\"failed to load fcn8s\")\n",
    "    #     return\n",
    "\n",
    "    conv1x1 = keras.layers.Conv2D(n_classes, 1, padding=\"same\", activation=\"softmax\")\n",
    "\n",
    "    input_layer = keras.layers.Input([None, None, 3])\n",
    "    output_model_fcn = model_fcn(input_layer)\n",
    "    output_model_fpn = model_fpn(input_layer)\n",
    "    output = output_model_fcn * output_model_fpn\n",
    "    output_final = conv1x1(output)\n",
    "\n",
    "    return keras.Model([input_layer], [output_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49bb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network must OUTPUT in logits [-inf, inf]\n",
    "# make sure input dimension is [B, H, W, C]\n",
    "def Jindex(target, pred, showPerChannel=False):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    if showPerChannel:\n",
    "        return (intersection + 0.1) / (union + 0.1)\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "\n",
    "def Dice(target, pred):\n",
    "    intersection = tf.reduce_sum(2 * pred * target, [0, 1, 2])\n",
    "    union = tf.reduce_sum(pred + target, [0, 1, 2])\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca707f",
   "metadata": {},
   "source": [
    "# Testing starts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc0735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_model/unetfpn\\\\ckpt-20'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "# UNET + FPN\n",
    "###################################\n",
    "\n",
    "\n",
    "# this iteration is calculated fom 160 iteration from\n",
    "# paper\n",
    "name = 'unetfpn'\n",
    "n_classes = 8\n",
    "batch_size = 8\n",
    "trainds = create_ds(batch_size)\n",
    "testds = create_ds(batch_size, False)\n",
    "\n",
    "# currently testing combined model performance\n",
    "model = combined_model_unetfpn()\n",
    "optimizer = keras.optimizers.Adam(1e-5)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model/unetfpn\", 5)\n",
    "ckptmg.restore_or_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3096d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# # FCN + FPN\n",
    "# ####################################\n",
    "\n",
    "\n",
    "# # this iteration is calculated fom 160 iteration from\n",
    "# # paper\n",
    "# name = 'fcnfpn'\n",
    "# n_classes = 8\n",
    "# batch_size = 8\n",
    "# trainds = create_ds(batch_size)\n",
    "# testds = create_ds(batch_size, False)\n",
    "\n",
    "# # currently testing combined model performance\n",
    "# model = combined_model_fcnfpn()\n",
    "# optimizer = keras.optimizers.Adam(1e-5)\n",
    "\n",
    "# ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "# ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model/fcnfpn\", 5)\n",
    "# ckptmg.restore_or_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa982a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.6134033  0.71653223 0.7726583  0.73893046 0.5548677  0.5365155\n",
      " 0.610026   0.5728834 ], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# evaluate on training set\n",
    "iteration = 0\n",
    "iou = tf.zeros([8])\n",
    "for bs_images, bs_label in trainds:\n",
    "    output = model(bs_images, training=False)\n",
    "    iou += Jindex(bs_label, output, showPerChannel=True)\n",
    "    iteration += 1\n",
    "\n",
    "\n",
    "print(iou / iteration)\n",
    "# evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "thisresults = iou / iteration\n",
    "thisresults = thisresults.numpy()\n",
    "thisresults = thisresults.tolist()\n",
    "thisresults = [\"unetfpn\"] + thisresults\n",
    "\n",
    "results = pd.DataFrame(thisresults).T\n",
    "results.columns = [\"model\", \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\"]\n",
    "\n",
    "prev_results = pd.read_csv(\n",
    "    \"results.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=0\n",
    ")\n",
    "prev_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57f9fd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcnfpn</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.606865</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.56549</td>\n",
       "      <td>0.605201</td>\n",
       "      <td>0.396585</td>\n",
       "      <td>0.423346</td>\n",
       "      <td>0.270381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model        c1        c2        c3       c4        c5        c6  \\\n",
       "0  fcnfpn  0.006966  0.606865  0.688877  0.56549  0.605201  0.396585   \n",
       "\n",
       "         c7        c8  \n",
       "0  0.423346  0.270381  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_results = pd.read_csv(\n",
    "    \"results.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=0\n",
    ")\n",
    "prev_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dedbe27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([prev_results, results], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2a59c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54802ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='variable', ylabel='value'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.barplot(data=results.melt(id_vars='model').drop_duplicates(), y='value', x='variable', hue='model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dca2d9a51fdadebd09e3ccb40442082e921fde9df61fd8be5d23c74deaf3a56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

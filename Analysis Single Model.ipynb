{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448e19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77180702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# [w, h, c], 448, 448, 3\n",
    "def decode_crop(image, label):\n",
    "    image = image[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "    label = label[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for index in range(4 * 8):\n",
    "        x, y = index // 8, index % 8\n",
    "        img_array.append(image[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "        label_array.append(label[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((img_array, label_array))\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append((label[:, :, 0] == 0) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0))\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 64) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 0) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 0) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 192) & (label[:, :, 1] == 0) & (label[:, :, 2] == 192)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 64) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, istrain=True, maximage=False):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    if istrain:\n",
    "        directory = 'C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Images/*.png'\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Labels/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "    else:\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Images/*.png\"\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Labels/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.cache()\n",
    "    if istrain:\n",
    "        ds = ds.shuffle(6400, SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(get_image_decode, AUTOTUNE)\n",
    "\n",
    "    if not maximage:\n",
    "        ds = ds.flat_map(decode_crop)\n",
    "\n",
    "    ds = ds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # batch and prefetch\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    if istrain:\n",
    "        ds = ds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ef5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=False)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "        m_all = self.final_activation(m_all)\n",
    "\n",
    "        return m_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebebd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_3 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_4 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(4, 4),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv1_o, conv2_o, conv3_o, conv4_o = self.backbone(images, training=False)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv4_o) + conv3_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv2_o\n",
    "        fcn_4x = self.upscale2x_3(fcn_8x) + conv1_o\n",
    "        final_output = self.upscale2x_4(fcn_4x)\n",
    "        final_output = self.final_activation(final_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6385667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network must OUTPUT in logits [-inf, inf]\n",
    "# make sure input dimension is [B, H, W, C]\n",
    "def Jindex(target, pred, showPerChannel=False):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    if showPerChannel:\n",
    "        return (intersection + 0.1) / (union + 0.1)\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "\n",
    "def Dice(target, pred):\n",
    "    intersection = tf.reduce_sum(2 * pred * target, [0, 1, 2])\n",
    "    union = tf.reduce_sum(pred + target, [0, 1, 2])\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d00152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# lr = 0.001 is good but spiky, next learning rate to test is 0.0005\n",
    "# both fpn and unet uses 1e-4 learning rate\n",
    "\n",
    "# test_fpn, lr = 0.00001 (1e-4)\n",
    "# lr=1e-6, slow \n",
    "# lr=1e-5, fast\n",
    "# lr=5e-5, can trained but stagnate at 12k with iou of 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e43513d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_model/fpn\\\\ckpt-20'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_choice = 2\n",
    "model_selection = [\"fcn8s\", \"unet\", \"fpn\"]\n",
    "name_model = model_selection[model_choice]\n",
    "\n",
    "n_classes = 8\n",
    "batch_size = 8\n",
    "trainds = create_ds(batch_size)\n",
    "testds = create_ds(batch_size, False)\n",
    "\n",
    "\n",
    "if model_choice == 0:\n",
    "    model = FCN_ORIG(n_classes)\n",
    "elif model_choice == 1:\n",
    "    model = sm.Unet(\n",
    "        backbone_name=\"efficientnetb0\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        encoder_freeze=False,\n",
    "        activation=\"softmax\",\n",
    "        classes=n_classes,\n",
    "        decoder_use_batchnorm=False,\n",
    "    )\n",
    "elif model_choice == 2:\n",
    "    model = FCN(8)\n",
    "else:\n",
    "    assert \"No model chosen\"\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(1e-5)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model/{name_model}\", 5)\n",
    "ckptmg.restore_or_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b629441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.6437473  0.7376864  0.75668824 0.7663384  0.6092268  0.52893275\n",
      " 0.5022663  0.3759207 ], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# evaluate on training set\n",
    "iteration = 0\n",
    "iou = tf.zeros([8])\n",
    "for bs_images, bs_label in trainds:\n",
    "    output = model(bs_images, training=False)\n",
    "    iou += Jindex(bs_label, output, showPerChannel=True)\n",
    "    iteration += 1\n",
    "\n",
    "\n",
    "print(iou / iteration)\n",
    "# evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9adc6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "thisresults = iou / iteration\n",
    "thisresults = thisresults.numpy()\n",
    "thisresults = thisresults.tolist()\n",
    "thisresults = [name_model] + thisresults\n",
    "\n",
    "results = pd.DataFrame(thisresults).T\n",
    "results.columns = [\"model\", \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\"]\n",
    "\n",
    "prev_results = pd.read_csv(\n",
    "    \"results.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "results = pd.concat([prev_results, results], axis=0)\n",
    "results.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ec0712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcnfpn</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.606865</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.56549</td>\n",
       "      <td>0.605201</td>\n",
       "      <td>0.396585</td>\n",
       "      <td>0.423346</td>\n",
       "      <td>0.270381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unetfpn</td>\n",
       "      <td>0.613403</td>\n",
       "      <td>0.716532</td>\n",
       "      <td>0.772658</td>\n",
       "      <td>0.73893</td>\n",
       "      <td>0.554868</td>\n",
       "      <td>0.536515</td>\n",
       "      <td>0.610026</td>\n",
       "      <td>0.572883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcn</td>\n",
       "      <td>0.342261</td>\n",
       "      <td>0.482714</td>\n",
       "      <td>0.534229</td>\n",
       "      <td>0.488029</td>\n",
       "      <td>0.162115</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.021107</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unet</td>\n",
       "      <td>0.460053</td>\n",
       "      <td>0.630666</td>\n",
       "      <td>0.603314</td>\n",
       "      <td>0.62563</td>\n",
       "      <td>0.41712</td>\n",
       "      <td>0.418332</td>\n",
       "      <td>0.358954</td>\n",
       "      <td>0.185025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fpn</td>\n",
       "      <td>0.643747</td>\n",
       "      <td>0.737686</td>\n",
       "      <td>0.756688</td>\n",
       "      <td>0.766338</td>\n",
       "      <td>0.609227</td>\n",
       "      <td>0.528933</td>\n",
       "      <td>0.502266</td>\n",
       "      <td>0.375921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        c1        c2        c3        c4        c5        c6  \\\n",
       "0   fcnfpn  0.006966  0.606865  0.688877   0.56549  0.605201  0.396585   \n",
       "0  unetfpn  0.613403  0.716532  0.772658   0.73893  0.554868  0.536515   \n",
       "0      fcn  0.342261  0.482714  0.534229  0.488029  0.162115  0.024922   \n",
       "0     unet  0.460053  0.630666  0.603314   0.62563   0.41712  0.418332   \n",
       "0      fpn  0.643747  0.737686  0.756688  0.766338  0.609227  0.528933   \n",
       "\n",
       "         c7        c8  \n",
       "0  0.423346  0.270381  \n",
       "0  0.610026  0.572883  \n",
       "0  0.021107  0.000905  \n",
       "0  0.358954  0.185025  \n",
       "0  0.502266  0.375921  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6fe5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.445464\n",
       "0    0.639477\n",
       "0    0.257035\n",
       "0    0.462387\n",
       "0    0.615101\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[:, 1:].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdae9175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='variable', ylabel='value'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fg, ax = plt.subplots(figsize=(15, 7))\n",
    "ax.set_xlabel('class')\n",
    "sb.barplot(data=results.melt(id_vars='model').drop_duplicates(), y='value', x='variable', hue='model', ax=ax)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dca2d9a51fdadebd09e3ccb40442082e921fde9df61fd8be5d23c74deaf3a56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448e19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77180702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# [w, h, c], 448, 448, 3\n",
    "def decode_crop(image, label):\n",
    "    image = image[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "    label = label[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for index in range(4 * 8):\n",
    "        x, y = index // 8, index % 8\n",
    "        img_array.append(image[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "        label_array.append(label[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((img_array, label_array))\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append((label[:, :, 0] == 0) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0))\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 64) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 0) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 0) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 192) & (label[:, :, 1] == 0) & (label[:, :, 2] == 192)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 64) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, istrain=True, maximage=False):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    if istrain:\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Images/*.png\"\n",
    "        )\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Labels/*.png\"\n",
    "        )\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "    else:\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Images/*.png\"\n",
    "        )\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = (\n",
    "            \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Labels/*.png\"\n",
    "        )\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.cache()\n",
    "    if istrain:\n",
    "        ds = ds.shuffle(6400, SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(get_image_decode, AUTOTUNE)\n",
    "\n",
    "    if not maximage:\n",
    "        ds = ds.flat_map(decode_crop)\n",
    "\n",
    "    ds = ds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # batch and prefetch\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    if istrain:\n",
    "        ds = ds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ef5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=False)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "        m_all = self.final_activation(m_all)\n",
    "\n",
    "        return m_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebebd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_3 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_4 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(4, 4),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv1_o, conv2_o, conv3_o, conv4_o = self.backbone(images, training=False)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv4_o) + conv3_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv2_o\n",
    "        fcn_4x = self.upscale2x_3(fcn_8x) + conv1_o\n",
    "        final_output = self.upscale2x_4(fcn_4x)\n",
    "        final_output = self.final_activation(final_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6385667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network must OUTPUT in logits [-inf, inf]\n",
    "# make sure input dimension is [B, H, W, C]\n",
    "def Jindex(target, pred, showPerChannel=False):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    if showPerChannel:\n",
    "        return (intersection + 0.1) / (union + 0.1)\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "\n",
    "def Dice(target, pred):\n",
    "    intersection = tf.reduce_sum(2 * pred * target, [0, 1, 2])\n",
    "    union = tf.reduce_sum(pred + target, [0, 1, 2])\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787661dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, trainds, testds):\n",
    "    # evaluate on training set\n",
    "    iteration = 0\n",
    "    iou = tf.zeros([8])\n",
    "    for bs_images, bs_label in trainds:\n",
    "        output = model(bs_images, training=False)\n",
    "        iou += Jindex(bs_label, output, showPerChannel=True)\n",
    "        iteration += 1\n",
    "    train_iou = iou / iteration\n",
    "\n",
    "    # evaluate on test set\n",
    "    iteration = 0\n",
    "    iou = tf.zeros([8])\n",
    "    for bs_images, bs_label in testds:\n",
    "        output = model(bs_images, training=False)\n",
    "        iou += Jindex(bs_label, output, showPerChannel=True)\n",
    "        iteration += 1\n",
    "    test_iou = iou / iteration\n",
    "\n",
    "    print(f'Train IoU: {train_iou} | Train IoU: {test_iou}')\n",
    "\n",
    "    return train_iou, test_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40870d",
   "metadata": {},
   "source": [
    "# Testing starts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ecc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = 2\n",
    "model_selection = [\"fcn8s\", \"unet\", \"fpn\"]\n",
    "name_model = model_selection[model_choice]\n",
    "\n",
    "n_classes = 8\n",
    "batch_size = 8\n",
    "trainds = create_ds(batch_size)\n",
    "testds = create_ds(batch_size, False)\n",
    "iou_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705123fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing fcn8s\n",
    "name = \"fcn\"\n",
    "model = FCN_ORIG(n_classes)\n",
    "optimizer = keras.optimizers.Adam(1e-5)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model/fcn8s\", 5)\n",
    "ckptmg.restore_or_initialize()\n",
    "\n",
    "train_iou, test_iou = eval_model(model, trainds, testds)\n",
    "iou_list.append([name, train_iou, test_iou])\n",
    "keras.backend.clear_session()\n",
    "del model\n",
    "del optimizer\n",
    "\n",
    "# testing unet\n",
    "name = \"unet\"\n",
    "model = sm.Unet(\n",
    "    backbone_name=\"efficientnetb0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_freeze=False,\n",
    "    activation=\"softmax\",\n",
    "    classes=n_classes,\n",
    "    decoder_use_batchnorm=False,\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(1e-5)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model/fcn8s\", 5)\n",
    "ckptmg.restore_or_initialize()\n",
    "\n",
    "train_iou, test_iou = eval_model(model, trainds, testds)\n",
    "iou_list.append([name, train_iou, test_iou])\n",
    "keras.backend.clear_session()\n",
    "del model\n",
    "del optimizer\n",
    "\n",
    "# testing fpn\n",
    "name = \"fpn\"\n",
    "model = FCN(8)\n",
    "optimizer = keras.optimizers.Adam(1e-5)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model/fcn8s\", 5)\n",
    "ckptmg.restore_or_initialize()\n",
    "\n",
    "train_iou, test_iou = eval_model(model, trainds, testds)\n",
    "iou_list.append([name, train_iou, test_iou])\n",
    "keras.backend.clear_session()\n",
    "del model\n",
    "del optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d28e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    return np.concatenate([[x[0]], x[1].numpy(), x[2].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    list(map(convert, iou_list)),\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"trainc1\",\n",
    "        \"trainc2\",\n",
    "        \"trainc3\",\n",
    "        \"trainc4\",\n",
    "        \"trainc5\",\n",
    "        \"trainc6\",\n",
    "        \"trainc7\",\n",
    "        \"trainc8\",\n",
    "        \"testc1\",\n",
    "        \"testc2\",\n",
    "        \"testc3\",\n",
    "        \"testc4\",\n",
    "        \"testc5\",\n",
    "        \"testc6\",\n",
    "        \"testc7\",\n",
    "        \"testc8\",\n",
    "    ],\n",
    ")\n",
    "second = results.pop('model')\n",
    "\n",
    "results.iloc[:, 0:] = results.iloc[:, 0:].astype('float')\n",
    "results['model'] = second\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdae9175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'IoU')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fg, ax = plt.subplots(figsize=(15, 7))\n",
    "sb.barplot(data=results.melt(id_vars='model').drop_duplicates(), y='value', x='variable', hue='model', ax=ax)\n",
    "ax.set_xlabel('class')\n",
    "ax.set_ylabel('IoU')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dca2d9a51fdadebd09e3ccb40442082e921fde9df61fd8be5d23c74deaf3a56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

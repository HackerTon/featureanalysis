{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from pathlib import Path\n",
    "\n",
    "# disable GPU computation\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# [w, h, c], 448, 448, 3\n",
    "def decode_crop(image, label):\n",
    "    image = image[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "    label = label[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for index in range(4 * 8):\n",
    "        x, y = index // 8, index % 8\n",
    "        img_array.append(image[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "        label_array.append(label[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((img_array, label_array))\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append((label[:, :, 0] == 0) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0))\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 64) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 0) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 0) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 192) & (label[:, :, 1] == 0) & (label[:, :, 2] == 192)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 64) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, istrain=True, maximage=False):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    if istrain:\n",
    "        directory = 'C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Images/*.png'\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Labels/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "    else:\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Images/*.png\"\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_val/**/Labels/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.cache()\n",
    "    if istrain:\n",
    "        ds = ds.shuffle(6400, SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(get_image_decode, AUTOTUNE)\n",
    "\n",
    "    if not maximage:\n",
    "        ds = ds.flat_map(decode_crop)\n",
    "\n",
    "    ds = ds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # batch and prefetch\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    if istrain:\n",
    "        ds = ds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = create_ds(1, maximage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = keras.applications.EfficientNetB0(weights='imagenet', include_top=False\n",
    "    )\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=False)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "        m_all = self.final_activation(m_all)\n",
    "\n",
    "        return m_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale8x = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(16, 16),\n",
    "            strides=(8, 8),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        _, conv1_o, conv2_o, conv3_o = self.backbone(images, training=training)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv3_o) + conv2_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv1_o\n",
    "        final_output = self.upscale8x(fcn_8x)\n",
    "        final_output = self.final_activation(final_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = create_ds(1, False, True)\n",
    "train = create_ds(1, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating pictures and save it as picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_model/fpn\\\\ckpt-20'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this iteration is calculated fom 160 iteration from\n",
    "# paper\n",
    "n_classes = 8\n",
    "model = FCN(8)\n",
    "# model = sm.Unet(backbone_name='resnet50', encoder_weights='imagenet', encoder_freeze=False, activation='softmax', classes=8)\n",
    "# model = FCN_ORIG(8)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "model_name = [\n",
    "    \"trained_model/fpn\", #fpn\n",
    "    \"trained_model/unet\", #unet\n",
    "    \"trained_model/fcn8s\", #fcn8s\n",
    "]\n",
    "\n",
    "# load model from the specific model\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"{model_name[0]}\", 5)\n",
    "# ckptmg = tf.train.CheckpointManager(ckpt, \"FPN/\", 5)\n",
    "ckptmg.restore_or_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_attributes(directory, input_img, input_label, output_img):\n",
    "    path = Path(directory)\n",
    "\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(path.joinpath(f\"oi.jpg\").absolute(), \"wb+\") as file_oi:\n",
    "        # STEP 1, write here\n",
    "        input_img_uint8 = tf.cast(input_img[0], tf.uint8)\n",
    "        byte = tf.image.encode_jpeg(input_img_uint8)\n",
    "        file_oi.write(byte.numpy())\n",
    "\n",
    "    for i in range(8):\n",
    "        channel_path = path.joinpath(f\"channel_{i}\")\n",
    "        channel_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # STEP 2, write here\n",
    "        output_img_softmax = tf.math.softmax(output_img, -1)\n",
    "        with open(channel_path.joinpath(f\"sm.jpg\").absolute(), \"wb+\") as file_sm:\n",
    "            output_img_softmax = tf.cast(\n",
    "                output_img[0, ..., i][..., tf.newaxis] * 255, tf.uint8\n",
    "            )\n",
    "            byte = tf.image.encode_jpeg(output_img_softmax)\n",
    "            file_sm.write(byte.numpy())\n",
    "\n",
    "        # STEP 3, write here\n",
    "        np.savetxt(\n",
    "            channel_path.joinpath(f\"pm.csv\").absolute(),\n",
    "            output_img_softmax[..., 0],\n",
    "            fmt=\"%3u\",\n",
    "        )\n",
    "\n",
    "        # STEP 4, write here\n",
    "        with open(channel_path.joinpath(f\"gsm.jpg\").absolute(), \"wb+\") as file_gsm:\n",
    "            input_label_uint8 = tf.cast(\n",
    "                input_label[0, ..., i][..., tf.newaxis] * 255, tf.uint8\n",
    "            )\n",
    "            byte = tf.image.encode_jpeg(input_label_uint8)\n",
    "            file_gsm.write(byte.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lenovo\\featureanalysis\\Generate All Images.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000012?line=5'>6</a>\u001b[0m \u001b[39m# d = sm.get_preprocessing('resnet50')(d)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000012?line=6'>7</a>\u001b[0m output_img \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(model(input_img_padded, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), tf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000012?line=8'>9</a>\u001b[0m save_attributes(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./train/fpn/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mstr\u001b[39;49m(idx)\u001b[39m.\u001b[39;49mzfill(\u001b[39m3\u001b[39;49m)\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, input_img_padded, input_label_padded, output_img)\n",
      "\u001b[1;32mc:\\Users\\lenovo\\featureanalysis\\Generate All Images.ipynb Cell 10'\u001b[0m in \u001b[0;36msave_attributes\u001b[1;34m(directory, input_img, input_label, output_img)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=22'>23</a>\u001b[0m     file_sm\u001b[39m.\u001b[39mwrite(byte\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=24'>25</a>\u001b[0m \u001b[39m# STEP 3, write here\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=25'>26</a>\u001b[0m np\u001b[39m.\u001b[39;49msavetxt(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=26'>27</a>\u001b[0m     channel_path\u001b[39m.\u001b[39;49mjoinpath(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpm.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mabsolute(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=27'>28</a>\u001b[0m     output_img_softmax[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=28'>29</a>\u001b[0m     fmt\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m%3u\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=29'>30</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=31'>32</a>\u001b[0m \u001b[39m# STEP 4, write here\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/Generate%20All%20Images.ipynb#ch0000011?line=32'>33</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(channel_path\u001b[39m.\u001b[39mjoinpath(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgsm.jpg\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mabsolute(), \u001b[39m\"\u001b[39m\u001b[39mwb+\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file_gsm:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\numpy\\lib\\npyio.py:1455\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/numpy/lib/npyio.py?line=1450'>1451</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/numpy/lib/npyio.py?line=1451'>1452</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMismatch between array dtype (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m) and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/numpy/lib/npyio.py?line=1452'>1453</a>\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mformat specifier (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/numpy/lib/npyio.py?line=1453'>1454</a>\u001b[0m                             \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(X\u001b[39m.\u001b[39mdtype), \u001b[39mformat\u001b[39m)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/numpy/lib/npyio.py?line=1454'>1455</a>\u001b[0m         fh\u001b[39m.\u001b[39;49mwrite(v)\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/numpy/lib/npyio.py?line=1456'>1457</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(footer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/numpy/lib/npyio.py?line=1457'>1458</a>\u001b[0m     footer \u001b[39m=\u001b[39m footer\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m comments)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, (input_img, input_label) in enumerate(train.take(20)):\n",
    "    # add 8 padding horizontally\n",
    "    input_img_padded = tf.pad(input_img, [[0, 0], [8, 8], [0, 0], [0, 0]])\n",
    "    input_label_padded = tf.pad(input_label, [[0, 0], [8, 8], [0, 0], [0, 0]])\n",
    "\n",
    "    # d = sm.get_preprocessing('resnet50')(d)\n",
    "    output_img = tf.cast(model(input_img_padded, training=False), tf.float32)\n",
    "\n",
    "    save_attributes(f\"./train/fpn/{str(idx).zfill(3)}\", input_img_padded, input_label_padded, output_img)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0beed873570eadf18b27de988f74387134654fe26ad0c1ed6b53170102862c4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf21': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

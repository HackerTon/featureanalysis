{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448e19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77180702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# [w, h, c], 448, 448, 3\n",
    "def decode_crop(image, label):\n",
    "    image = image[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "    label = label[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for index in range(4 * 8):\n",
    "        x, y = index // 8, index % 8\n",
    "        img_array.append(image[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "        label_array.append(label[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((img_array, label_array))\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append((label[:, :, 0] == 0) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0))\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 64) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 0) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 0) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 192) & (label[:, :, 1] == 0) & (label[:, :, 2] == 192)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 64) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, istrain=True, maximage=False):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    if istrain:\n",
    "        directory = 'C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Images/*.png'\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_train/**/Images/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "    else:\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_test/**/Images/*.png\"\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"C:/home/dataset/uavid_v1.5_official_release/uavid_test/**/Images/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.cache()\n",
    "    if istrain:\n",
    "        ds = ds.shuffle(6400, SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(get_image_decode, AUTOTUNE)\n",
    "\n",
    "    if not maximage:\n",
    "        ds = ds.flat_map(decode_crop)\n",
    "\n",
    "    ds = ds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # batch and prefetch\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    if istrain:\n",
    "        ds = ds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, input_shape=[448, 448, 3]\n",
    "    )\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ef5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=training)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "        conv5_p = self.conv5_bn(conv5_p, training=training)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "        conv4_p = self.conv4_bn(conv4_p, training=training)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "        conv3_p = self.conv3_bn(conv3_p, training=training)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "        conv2_p = self.conv2_bn(conv2_p, training=training)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.bnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.bnorm(m_all, training=training)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "        m_all = self.final_activation(m_all)\n",
    "\n",
    "        return m_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebebd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.bnorm1 = keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.bnorm2 = keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.bnorm3 = keras.layers.BatchNormalization()\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_3 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_4 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(4, 4),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv1_o, conv2_o, conv3_o, conv4_o = self.backbone(images, training=training)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv1_o = self.bnorm1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv2_o = self.bnorm2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "        conv3_o = self.bnorm3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv4_o) + conv3_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv2_o\n",
    "        fcn_4x = self.upscale2x_3(fcn_8x) + conv1_o\n",
    "        final_output = self.upscale2x_4(fcn_4x)\n",
    "        final_output = self.final_activation(final_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6385667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network must OUTPUT in logits [-inf, inf]\n",
    "# make sure input dimension is [B, H, W, C]\n",
    "def Jindex(target, pred):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "\n",
    "def Dice(target, pred):\n",
    "    intersection = tf.reduce_sum(2 * pred * target, [0, 1, 2])\n",
    "    union = tf.reduce_sum(pred + target, [0, 1, 2])\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d00152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# lr = 0.001 is good but spiky, next learning rate to test is 0.0005\n",
    "# both fpn and unet uses 1e-4 learning rate\n",
    "\n",
    "# test_fpn, lr = 0.00001 (1e-4)\n",
    "# lr=1e-6, slow \n",
    "# lr=1e-5, fast\n",
    "# lr=5e-5, can trained but stagnate at 12k with iou of 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e43513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this iteration is calculated fom 160 iteration from\n",
    "# paper\n",
    "\n",
    "model_selection = [\"fcn8s\", \"unet\", \"fpn\"]\n",
    "model_choice = 0\n",
    "name_model = model_selection[model_choice]\n",
    "\n",
    "n_epoch = 20\n",
    "n_classes = 8\n",
    "batch_size = 8\n",
    "trainds = create_ds(batch_size)\n",
    "testds = create_ds(batch_size, False)\n",
    "\n",
    "\n",
    "if model_choice == 0:\n",
    "    model = FCN_ORIG(n_classes)\n",
    "elif model_choice == 1:\n",
    "    model = sm.Unet(backbone_name='efficientnetb0', encoder_weights='imagenet', encoder_freeze=False, activation='softmax', classes=n_classes)\n",
    "elif model_choice == 2:\n",
    "    model = FCN(8)\n",
    "else:\n",
    "    assert \"No model chosen\"\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f'trained_model/{name_model}', 5)\n",
    "ckptmg.restore_or_initialize()\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = f'logs/{name_model}/{current_time}/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_log_dir = f'logs/{name_model}/{current_time}/test'\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d66a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n",
      "(8, 448, 448, 8)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lenovo\\featureanalysis\\project_fcn8s.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/project_fcn8s.ipynb#ch0000009?line=14'>15</a>\u001b[0m     output \u001b[39m=\u001b[39m model(bs_images, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/project_fcn8s.ipynb#ch0000009?line=15'>16</a>\u001b[0m     c_loss \u001b[39m=\u001b[39m dice_loss(bs_labels, output) \u001b[39m+\u001b[39m ALPHA \u001b[39m*\u001b[39m focal_loss(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/project_fcn8s.ipynb#ch0000009?line=16'>17</a>\u001b[0m         bs_labels, output\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/project_fcn8s.ipynb#ch0000009?line=17'>18</a>\u001b[0m     )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/project_fcn8s.ipynb#ch0000009?line=19'>20</a>\u001b[0m grad \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mgradient(c_loss, model\u001b[39m.\u001b[39;49mtrainable_variables)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/project_fcn8s.ipynb#ch0000009?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grad, model\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenovo/featureanalysis/project_fcn8s.ipynb#ch0000009?line=21'>22</a>\u001b[0m sum_loss \u001b[39m=\u001b[39m c_loss\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1081\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1076'>1077</a>\u001b[0m \u001b[39mif\u001b[39;00m output_gradients \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1077'>1078</a>\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1078'>1079</a>\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten(output_gradients)]\n\u001b[1;32m-> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1080'>1081</a>\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1081'>1082</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1082'>1083</a>\u001b[0m     flat_targets,\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1083'>1084</a>\u001b[0m     flat_sources,\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1084'>1085</a>\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1085'>1086</a>\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1086'>1087</a>\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1088'>1089</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1089'>1090</a>\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=1090'>1091</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=62'>63</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=63'>64</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=64'>65</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=66'>67</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=67'>68</a>\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=68'>69</a>\u001b[0m     target,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=69'>70</a>\u001b[0m     sources,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=70'>71</a>\u001b[0m     output_gradients,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=71'>72</a>\u001b[0m     sources_raw,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=72'>73</a>\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:156\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=153'>154</a>\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=154'>155</a>\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=155'>156</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=156'>157</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/eager/backprop.py?line=157'>158</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:266\u001b[0m, in \u001b[0;36m_MeanGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_grad.py?line=262'>263</a>\u001b[0m   output_shape \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(op\u001b[39m.\u001b[39moutputs[\u001b[39m0\u001b[39m])\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_grad.py?line=263'>264</a>\u001b[0m   factor \u001b[39m=\u001b[39m _safe_shape_div(\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_grad.py?line=264'>265</a>\u001b[0m       math_ops\u001b[39m.\u001b[39mreduce_prod(input_shape), math_ops\u001b[39m.\u001b[39mreduce_prod(output_shape))\n\u001b[1;32m--> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_grad.py?line=265'>266</a>\u001b[0m \u001b[39mreturn\u001b[39;00m math_ops\u001b[39m.\u001b[39;49mtruediv(sum_grad, math_ops\u001b[39m.\u001b[39;49mcast(factor, sum_grad\u001b[39m.\u001b[39;49mdtype)), \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1079'>1080</a>\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1080'>1081</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1081'>1082</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1082'>1083</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1083'>1084</a>\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1084'>1085</a>\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1085'>1086</a>\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1589\u001b[0m, in \u001b[0;36mtruediv\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1557'>1558</a>\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.truediv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtruediv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1558'>1559</a>\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1559'>1560</a>\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1560'>1561</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtruediv\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1561'>1562</a>\u001b[0m   \u001b[39m\"\"\"Divides x / y elementwise (using Python 3 division operator semantics).\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1562'>1563</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1563'>1564</a>\u001b[0m \u001b[39m  NOTE: Prefer using the Tensor operator or tf.divide which obey Python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1586'>1587</a>\u001b[0m \u001b[39m    TypeError: If `x` and `y` have different dtypes.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1587'>1588</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1588'>1589</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _truediv_python3(x, y, name)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1527\u001b[0m, in \u001b[0;36m_truediv_python3\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1524'>1525</a>\u001b[0m   x \u001b[39m=\u001b[39m cast(x, dtype)\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1525'>1526</a>\u001b[0m   y \u001b[39m=\u001b[39m cast(y, dtype)\n\u001b[1;32m-> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/math_ops.py?line=1526'>1527</a>\u001b[0m \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mreal_div(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:7870\u001b[0m, in \u001b[0;36mreal_div\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=7867'>7868</a>\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=7868'>7869</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=7869'>7870</a>\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=7870'>7871</a>\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mRealDiv\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y)\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=7871'>7872</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   <a href='file:///c%3A/Users/lenovo/miniconda3/envs/tf_gpu_env/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=7872'>7873</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Real training\n",
    "train_iteration = 0\n",
    "iteration = 0\n",
    "sum_iou = 0\n",
    "sum_loss = 0\n",
    "ALPHA = 1.0\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    initial_time = time.time()\n",
    "    for bs_images, bs_labels in trainds:\n",
    "        if model_choice == 1:\n",
    "            bs_images = sm.get_preprocessing(\"efficientnetb0\")(bs_images)\n",
    "\n",
    "        with tf.GradientTape() as t:\n",
    "            output = model(bs_images, training=True)\n",
    "            c_loss = dice_loss(bs_labels, output) + ALPHA * focal_loss(\n",
    "                bs_labels, output\n",
    "            )\n",
    "\n",
    "        grad = t.gradient(c_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "        sum_loss = c_loss\n",
    "        train_iteration += 1\n",
    "\n",
    "        # calculate loss and IoU at iteration\n",
    "        # this is train\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar(\"loss\", c_loss, step=train_iteration)\n",
    "            tf.summary.scalar(\n",
    "                \"iou\", sm.metrics.iou_score(bs_labels, output), step=train_iteration\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1}, Time Taken: {round(time.time() - initial_time, 3)}s\"\n",
    "    )\n",
    "\n",
    "    for bs_images, bs_labels in testds:\n",
    "        output = model(bs_images, training=False)\n",
    "        sum_loss += (\n",
    "            dice_loss(bs_labels, output) + ALPHA * focal_loss(bs_labels, output)\n",
    "        ) * batch_size\n",
    "        sum_iou += sm.metrics.iou_score(bs_labels, output) * batch_size\n",
    "        iteration += batch_size\n",
    "\n",
    "    # calculate validation loss and IoU\n",
    "    # this is test\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar(\"loss\", sum_loss / iteration, step=train_iteration)\n",
    "        tf.summary.scalar(\"iou\", sum_iou / iteration, step=train_iteration)\n",
    "\n",
    "    iteration = 0\n",
    "    sum_iou = 0\n",
    "    sum_loss = 0\n",
    "    ckptmg.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b940ec",
   "metadata": {},
   "source": [
    "# To explain about LABELS\n",
    "\n",
    "1. Background Clutter (0, 0, 0)\n",
    "2. Building           (128, 0, 0)\n",
    "3. Road               (128, 64, 128)\n",
    "4. Tree               (0, 128, 0)\n",
    "5. Low Vegetation     (128, 128, 0)\n",
    "6. Moving Car         (64, 0, 128)\n",
    "7. Static Car         (192, 0, 192)\n",
    "8. Human              (64, 64, 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dca2d9a51fdadebd09e3ccb40442082e921fde9df61fd8be5d23c74deaf3a56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

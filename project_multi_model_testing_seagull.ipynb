{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816d00ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2dae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seagull_path(istrain=True):\n",
    "    directory = \"C:\\Alans\\seagull\"\n",
    "\n",
    "    if istrain:\n",
    "        trainimg = os.path.join(directory, \"trainimg\", \"*.jpg\")\n",
    "        images = glob.glob(trainimg, recursive=True)\n",
    "        trainmask = os.path.join(directory, \"trainmask\", \"*.jpg\")\n",
    "        labels = glob.glob(trainmask, recursive=True)\n",
    "    else:\n",
    "        testimg = os.path.join(directory, \"testimg\", \"*.jpg\")\n",
    "        images = glob.glob(testimg, recursive=True)\n",
    "        testmask = os.path.join(directory, \"testmask\", \"*.jpg\")\n",
    "        labels = glob.glob(testmask, recursive=True)\n",
    "\n",
    "    print(len(images), len(labels))\n",
    "\n",
    "    mask_set = set()\n",
    "    image_set = set()\n",
    "    for lbl in labels:\n",
    "        lbl = lbl.split('\\\\')[-1]\n",
    "        mask_set.add(lbl)\n",
    "\n",
    "    for img in images:\n",
    "        img = img.split('\\\\')[-1]\n",
    "        image_set.add(img)\n",
    "\n",
    "    complete_path = mask_set.intersection(image_set)\n",
    "    print(\n",
    "        f\"IMG - LBL NUM: {len(image_set.difference(mask_set))}, Intersection: {len(complete_path)}\"\n",
    "    )\n",
    "\n",
    "    return [i for i in complete_path]\n",
    "\n",
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def path_2_test(path):\n",
    "    return (\n",
    "        r\"C:\\Alans\\seagull\\\\testimg\\\\\" + path,\n",
    "        r\"C:\\Alans\\seagull\\\\testmask\\\\\" + path,\n",
    "    )\n",
    "\n",
    "\n",
    "def path_2_train(path):\n",
    "    return (\n",
    "        r\"C:\\Alans\\seagull\\trainimg\\\\\" + path,\n",
    "        r\"C:\\Alans\\seagull\\trainmask\\\\\" + path,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append(label[:, :, 0] == 0)\n",
    "    labels.append(label[:, :, 0] == 255)\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, ratio=0.8):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    paths = get_seagull_path()\n",
    "    ds1 = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds1 = ds1.map(path_2_train, AUTOTUNE)\n",
    "\n",
    "    paths = get_seagull_path(False)\n",
    "    ds2 = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds2 = ds2.map(path_2_test, AUTOTUNE)\n",
    "\n",
    "    ds = ds1.concatenate(ds2)\n",
    "    ds = ds.cache()\n",
    "\n",
    "    takefortrain = int(23124 * ratio)\n",
    "    trainds = ds.take(takefortrain)\n",
    "    testds = ds.skip(takefortrain).take(23124 - takefortrain)\n",
    "\n",
    "    trainds = trainds.shuffle(23124)\n",
    "\n",
    "    trainds = trainds.map(get_image_decode, AUTOTUNE)\n",
    "    trainds = trainds.map(get_mask, AUTOTUNE)\n",
    "    testds = testds.map(get_image_decode, AUTOTUNE)\n",
    "    testds = testds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # # batch and prefetch\n",
    "    trainds = trainds.batch(batch_size)\n",
    "    testds = testds.batch(batch_size)\n",
    "\n",
    "    trainds = trainds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return trainds, testds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ef5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=False)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "\n",
    "        return m_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebebd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_3 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_4 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(4, 4),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv1_o, conv2_o, conv3_o, conv4_o = self.backbone(images, training=False)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv4_o) + conv3_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv2_o\n",
    "        fcn_4x = self.upscale2x_3(fcn_8x) + conv1_o\n",
    "        final_output = self.upscale2x_4(fcn_4x)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcea6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescalingUnet(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(RescalingUnet, self).__init__()\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return ((inputs * (1 / 255.0)) - self.mean) / self.std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76060da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model_unetfpn(mode=\"multiply\", n_classes=8):\n",
    "    model_unet = sm.Unet(\n",
    "        backbone_name=\"efficientnetb0\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        encoder_freeze=False,\n",
    "        classes=n_classes,\n",
    "        decoder_use_batchnorm=False,\n",
    "        activation='linear'\n",
    "    )\n",
    "    model_fpn = FCN(n_classes)\n",
    "    conv1x1 = keras.layers.Conv2D(n_classes, 1, padding=\"same\", activation=\"softmax\")\n",
    "    input_layer = keras.layers.Input([None, None, 3])\n",
    "    rescale_layer = RescalingUnet()\n",
    "\n",
    "    if mode == \"concat\":\n",
    "        concat = keras.layers.Concatenate()\n",
    "\n",
    "    output_model_fcn = model_unet(rescale_layer(input_layer))\n",
    "    output_model_fpn = model_fpn(input_layer)\n",
    "\n",
    "    if mode == \"multiply\":\n",
    "        output = output_model_fcn * output_model_fpn\n",
    "    elif mode == \"sum\":\n",
    "        output = output_model_fcn + output_model_fpn\n",
    "    elif mode == \"concat\":\n",
    "        output = concat([output_model_fcn, output_model_fpn])\n",
    "    else:\n",
    "        raise AssertionError(\"mode selected is not in the list\")\n",
    "    output_final = conv1x1(output)\n",
    "    return keras.Model([input_layer], [output_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8de64f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model_fcnfpn(mode=\"multi\", n_classes=8):\n",
    "    model_fcn = FCN_ORIG(n_classes)\n",
    "    model_fpn = FCN(n_classes)\n",
    "\n",
    "    conv1x1 = keras.layers.Conv2D(n_classes, 1, padding=\"same\", activation=\"softmax\")\n",
    "\n",
    "    input_layer = keras.layers.Input([None, None, 3])\n",
    "    output_model_fcn = model_fcn(input_layer)\n",
    "    output_model_fpn = model_fpn(input_layer)\n",
    "    output = output_model_fcn * output_model_fpn\n",
    "    output_final = conv1x1(output)\n",
    "\n",
    "    return keras.Model([input_layer], [output_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49bb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network must OUTPUT in logits [-inf, inf]\n",
    "# make sure input dimension is [B, H, W, C]\n",
    "def Jindex(target, pred, showPerChannel=False):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    if showPerChannel:\n",
    "        return (intersection + 0.1) / (union + 0.1)\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "\n",
    "def Dice(target, pred):\n",
    "    intersection = tf.reduce_sum(2 * pred * target, [0, 1, 2])\n",
    "    union = tf.reduce_sum(pred + target, [0, 1, 2])\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ca70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, trainds, testds):\n",
    "    # evaluate on training set\n",
    "    iteration = 0\n",
    "    iou = tf.zeros([2])\n",
    "    for bs_images, bs_label in trainds:\n",
    "        output = model(bs_images, training=False)\n",
    "        iou += Jindex(bs_label, output, showPerChannel=True)\n",
    "        iteration += 1\n",
    "    train_iou = iou / iteration\n",
    "\n",
    "    # evaluate on test set\n",
    "    iteration = 0\n",
    "    iou = tf.zeros([2])\n",
    "    for bs_images, bs_label in testds:\n",
    "        output = model(bs_images, training=False)\n",
    "        iou += Jindex(bs_label, output, showPerChannel=True)\n",
    "        iteration += 1\n",
    "    test_iou = iou / iteration\n",
    "\n",
    "    print(f\"Train IoU: {train_iou} | Train IoU: {test_iou}\")\n",
    "\n",
    "    return train_iou, test_iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca707f",
   "metadata": {},
   "source": [
    "# Testing starts below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4999a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19373 17243\n",
      "IMG - LBL NUM: 10687, Intersection: 8686\n",
      "14476 14443\n",
      "IMG - LBL NUM: 38, Intersection: 14438\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "batch_size = 32\n",
    "trainds, testds = create_ds(batch_size)\n",
    "iou_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "948f2551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IoU: [0.63532674 0.00258795] | Train IoU: [0.63730085 0.00390037]\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# UNET(CONCAT) + FPN\n",
    "####################################\n",
    "name = \"unetfpnconcat\"\n",
    "model = combined_model_unetfpn(\"concat\", n_classes=2)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model_seagull/unetfpnconcat\", 5)\n",
    "ckptmg.restore_or_initialize()\n",
    "\n",
    "train_iou, test_iou = eval_model(model, trainds, testds)\n",
    "iou_list.append([name, train_iou, test_iou])\n",
    "keras.backend.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "203f93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    return np.concatenate([[x[0]], x[1].numpy(), x[2].numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ebb407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainc1</th>\n",
       "      <th>trainc2</th>\n",
       "      <th>testc1</th>\n",
       "      <th>testc2</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.635327</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.637301</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>unetfpnconcat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trainc1   trainc2    testc1  testc2          model\n",
       "0  0.635327  0.002588  0.637301  0.0039  unetfpnconcat"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    list(map(convert, iou_list)),\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"trainc1\",\n",
    "        \"trainc2\",\n",
    "        \"testc1\",\n",
    "        \"testc2\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "results.to_csv('results_multiple_seagull.csv')\n",
    "second = results.pop(\"model\")\n",
    "\n",
    "results.iloc[:, 0:] = results.iloc[:, 0:].astype(\"float\")\n",
    "results[\"model\"] = second\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54802ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fg, ax = plt.subplots(figsize=(15, 7))\n",
    "sb.barplot(\n",
    "    data=results.melt(id_vars=\"model\").drop_duplicates(),\n",
    "    y=\"value\",\n",
    "    x=\"variable\",\n",
    "    hue=\"model\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"class\")\n",
    "ax.set_ylabel(\"IoU\")\n",
    "ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f009644687fbff803937e34e13187dc56579602643eee9f001c34fd1c6bb4d9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 13:00:54.128517: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seagull_path(istrain=True):\n",
    "    directory = \"/home/hackerton/Downloads/Airbus + Seagull Dataset/\"\n",
    "\n",
    "    if istrain:\n",
    "        trainimg = os.path.join(directory, \"trainimg\", \"*.jpg\")\n",
    "        images = glob.glob(trainimg, recursive=True)\n",
    "        trainmask = os.path.join(directory, \"trainmask\", \"*.jpg\")\n",
    "        labels = glob.glob(trainmask, recursive=True)\n",
    "    else:\n",
    "        testimg = os.path.join(directory, \"testimg\", \"*.jpg\")\n",
    "        images = glob.glob(testimg, recursive=True)\n",
    "        testmask = os.path.join(directory, \"testmask\", \"*.jpg\")\n",
    "        labels = glob.glob(testmask, recursive=True)\n",
    "\n",
    "    print(len(images), len(labels))\n",
    "\n",
    "    mask_set = set()\n",
    "    image_set = set()\n",
    "    for lbl in labels:\n",
    "        lbl = lbl.split(\"/\")[-1]\n",
    "        mask_set.add(lbl)\n",
    "\n",
    "    for img in images:\n",
    "        img = img.split(\"/\")[-1]\n",
    "        image_set.add(img)\n",
    "\n",
    "    complete_path = mask_set.intersection(image_set)\n",
    "    print(\n",
    "        f\"IMG - LBL NUM: {len(image_set.difference(mask_set))}, Intersection: {len(complete_path)}\"\n",
    "    )\n",
    "\n",
    "    return [i for i in complete_path]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def path_2_test(path):\n",
    "    return (\n",
    "        \"/home/hackerton/Downloads/Airbus + Seagull Dataset/testimg/\" + path,\n",
    "        \"/home/hackerton/Downloads/Airbus + Seagull Dataset/testmask/\" + path,\n",
    "    )\n",
    "\n",
    "\n",
    "def path_2_train(path):\n",
    "    return (\n",
    "        \"/home/hackerton/Downloads/Airbus + Seagull Dataset/trainimg/\" + path,\n",
    "        \"/home/hackerton/Downloads/Airbus + Seagull Dataset/trainmask/\" + path,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append(label[:, :, 0] == 0)\n",
    "    labels.append(label[:, :, 0] == 255)\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, ratio=0.8):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    paths = get_seagull_path()\n",
    "    ds1 = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds1 = ds1.map(path_2_train, AUTOTUNE)\n",
    "\n",
    "    paths = get_seagull_path(False)\n",
    "    ds2 = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds2 = ds2.map(path_2_test, AUTOTUNE)\n",
    "\n",
    "    ds = ds1.concatenate(ds2)\n",
    "    ds = ds.cache()\n",
    "\n",
    "    takefortrain = int(23124 * ratio)\n",
    "    trainds = ds.take(takefortrain)\n",
    "    testds = ds.skip(takefortrain).take(23124 - takefortrain)\n",
    "\n",
    "    trainds = trainds.shuffle(23124)\n",
    "\n",
    "    trainds = trainds.map(get_image_decode, AUTOTUNE)\n",
    "    trainds = trainds.map(get_mask, AUTOTUNE)\n",
    "    testds = testds.map(get_image_decode, AUTOTUNE)\n",
    "    testds = testds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # # batch and prefetch\n",
    "    trainds = trainds.batch(batch_size)\n",
    "    testds = testds.batch(batch_size)\n",
    "\n",
    "    trainds = trainds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return trainds, testds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_background = 0\n",
    "# sum_ship = 0\n",
    "\n",
    "# trainds, testds = create_ds(1)\n",
    "\n",
    "# for _, label in trainds:\n",
    "#     sum_background += tf.reduce_sum(label[..., 0])\n",
    "#     sum_ship += tf.reduce_sum(label[..., 1])\n",
    "\n",
    "# total_sum = sum_background + sum_ship\n",
    "# print(\"ratio of weight\")\n",
    "# print(f\"BACKGROUND: {sum_background / total_sum}, SHIP: {sum_ship / total_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, label in trainds.take(2):\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(9, 16))\n",
    "#     axs[0].imshow(tf.cast(img[0], tf.int32))\n",
    "#     axs[1].imshow(tf.cast(label[0, ..., 0], tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = create_ds(1, False, True)\n",
    "# total_mask_sum = tf.zeros([8], tf.int64)\n",
    "# for image, mask in data:\n",
    "#     mask = tf.cast(mask, tf.int64)\n",
    "#     mask_sum = tf.reduce_sum(mask, [0, 1, 2])\n",
    "#     total_mask_sum += mask_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 7))\n",
    "# plt.bar([str(i) for i in range(8)], total_mask_sum / tf.reduce_max(total_mask_sum), color=['blue', 'red', 'green', 'yellow'], align='center', alpha=0.8)\n",
    "# plt.grid(True)\n",
    "# plt.title('The number of samples mask in each class')\n",
    "# (total_mask_sum / tf.reduce_mean(total_mask_sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone():\n",
    "    _backbone = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, input_shape=[None, None, 3]\n",
    "    )\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )\n",
    "\n",
    "\n",
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone()\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=training)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "        conv5_p = self.conv5_bn(conv5_p, training=training)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "        conv4_p = self.conv4_bn(conv4_p, training=training)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "        conv3_p = self.conv3_bn(conv3_p, training=training)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "        conv2_p = self.conv2_bn(conv2_p, training=training)\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN()\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.bnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.bnorm(m_all, training=training)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "        m_all = self.final_activation(m_all)\n",
    "\n",
    "        return m_all\n",
    "\n",
    "\n",
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale8x = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(16, 16),\n",
    "            strides=(8, 8),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        _, conv1_o, conv2_o, conv3_o = self.backbone(images, training=training)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv3_o) + conv2_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv1_o\n",
    "        final_output = self.upscale8x(fcn_8x)\n",
    "        final_output = self.final_activation(final_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network must OUTPUT in logits [-inf, inf]\n",
    "# make sure input dimension is [B, H, W, C]\n",
    "def Jindex(target, pred):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "\n",
    "def Dice(target, pred):\n",
    "    intersection = tf.reduce_sum(2 * pred * target, [0, 1, 2])\n",
    "    union = tf.reduce_sum(pred + target, [0, 1, 2])\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 13:00:56.646998: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-21 13:00:58.125348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.125686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 950M computeCapability: 5.0\n",
      "coreClock: 0.928GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-10-21 13:00:58.125723: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-21 13:00:58.129489: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-21 13:00:58.129566: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-21 13:00:58.130780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-21 13:00:58.131107: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-21 13:00:58.134708: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-21 13:00:58.135593: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-21 13:00:58.135797: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-21 13:00:58.135941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.136381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.136691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-21 13:00:58.137076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-21 13:00:58.137831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.138158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 950M computeCapability: 5.0\n",
      "coreClock: 0.928GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-10-21 13:00:58.138261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.138625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.138909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-21 13:00:58.138950: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-21 13:00:58.574240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-21 13:00:58.574270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-10-21 13:00:58.574279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-10-21 13:00:58.574480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.574829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.575131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-21 13:00:58.575374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1627 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = \"logs/tape/\" + current_time + \"/train\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_log_dir = \"logs/tape/\" + current_time + \"/test\"\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19373 17243\n",
      "IMG - LBL NUM: 10687, Intersection: 8686\n",
      "14476 14443\n",
      "IMG - LBL NUM: 38, Intersection: 14438\n"
     ]
    }
   ],
   "source": [
    "# this iteration is calculated fom 160 iteration from\n",
    "# paper\n",
    "n_epoch = 20\n",
    "n_classes = 2\n",
    "batch_size = 4\n",
    "trainds, testds = create_ds(batch_size)\n",
    "model = FCN(n_classes)\n",
    "# model = sm.Unet(backbone_name='resnet50', encoder_weights='imagenet', encoder_freeze=False, activation='softmax', classes=8)\n",
    "# model = FCN_ORIG(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=[0.001, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build([None, 448, 448, 3])\n",
    "\n",
    "# model.layers[0].backbone.trainable = False\n",
    "# for layer in model.layers[0].backbone.layers:\n",
    "#     layer.trainable = False\n",
    "#     if layer.name == 'block5a_activation':\n",
    "#         break\n",
    "\n",
    "# model.compile()\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, \"trained_model/seagull_fcn\", 5)\n",
    "ckptmg.restore_or_initialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure you configure the preprocessing for each model correctly.\n",
    "\n",
    "## FCN, FPN used Efficient and Unet used Resnet50\n",
    "\n",
    "1. ## Resnet50 needs input to be range [0, 1]\n",
    "2. ## Efficientnet need to range to be [0, 255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 13:01:01.047687: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-21 13:01:01.067658: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2693730000 Hz\n",
      "2021-10-21 13:01:01.313022: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-10-21 13:01:01.349180: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-21 13:01:01.622078: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2021-10-21 13:01:02.001295: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-21 13:01:02.213185: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-21 13:01:02.487222: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:03.149842: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:03.558352: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:04.721092: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:04.773560: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:05.437390: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 612.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:05.590918: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 612.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:06.060115: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 612.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:06.215527: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 612.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-10-21 13:01:06.659072: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 612.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "# Real training\n",
    "train_iteration = 0\n",
    "iteration = 0\n",
    "sum_iou = 0\n",
    "sum_loss = 0\n",
    "ALPHA = 1.0\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for bs_images, bs_labels in trainds:\n",
    "        # REMEMBER HERE\n",
    "        # Comment below if you are training FPN and ORIG_FCN\n",
    "        # bs_images = sm.get_preprocessing('resnet')(bs_images)\n",
    "\n",
    "        with tf.GradientTape() as t:\n",
    "            output = model(bs_images)\n",
    "            c_loss = dice_loss(bs_labels, output) + ALPHA * focal_loss(\n",
    "                bs_labels, output\n",
    "            )\n",
    "\n",
    "        grad = t.gradient(c_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "        sum_loss = c_loss\n",
    "        train_iteration += 1\n",
    "\n",
    "        # calculate loss and IoU at iteration\n",
    "        # this is train\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar(\"loss\", c_loss, step=train_iteration)\n",
    "            tf.summary.scalar(\"iou\", sm.metrics.iou_score(bs_labels, output), step=train_iteration)\n",
    "\n",
    "    for bs_images, bs_labels in testds:\n",
    "        output = model(bs_images, training=False)\n",
    "        sum_loss += (\n",
    "            dice_loss(bs_labels, output) + ALPHA * focal_loss(bs_labels, output)\n",
    "        ) * batch_size\n",
    "        sum_iou += sm.metrics.iou_score(bs_labels, output) * batch_size\n",
    "        iteration += batch_size\n",
    "\n",
    "    # calculate validation loss and IoU\n",
    "    # this is test\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar(\"loss\", sum_loss / iteration, step=train_iteration)\n",
    "        tf.summary.scalar(\"iou\", sum_iou / iteration, step=train_iteration)\n",
    "\n",
    "    iteration = 0\n",
    "    sum_iou = 0\n",
    "    sum_loss = 0\n",
    "    ckptmg.save()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0beed873570eadf18b27de988f74387134654fe26ad0c1ed6b53170102862c4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf21': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

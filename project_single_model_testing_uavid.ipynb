{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448e19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77180702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# [w, h, c], 448, 448, 3\n",
    "def decode_crop(image, label):\n",
    "    image = image[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "    label = label[368 // 2 : -(368 // 2), 256 // 2 : -(256 // 2)]\n",
    "\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for index in range(4 * 8):\n",
    "        x, y = index // 8, index % 8\n",
    "        img_array.append(image[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "        label_array.append(label[448 * x : 448 * (1 + x), 448 * y : 448 * (1 + y)])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((img_array, label_array))\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append((label[:, :, 0] == 0) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0))\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 0) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 64) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 0) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 128) & (label[:, :, 1] == 128) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 0) & (label[:, :, 2] == 128)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 192) & (label[:, :, 1] == 0) & (label[:, :, 2] == 192)\n",
    "    )\n",
    "    labels.append(\n",
    "        (label[:, :, 0] == 64) & (label[:, :, 1] == 64) & (label[:, :, 2] == 0)\n",
    "    )\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, istrain=True, maximage=False):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    if istrain:\n",
    "        directory = \"/home/hackerton/Downloads/uavid_v1.5_official_release/uavid_train/**/Images/*.png\"\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"/home/hackerton/Downloads/uavid_v1.5_official_release/uavid_train/**/Labels/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "    else:\n",
    "        directory = \"/home/hackerton/Downloads/uavid_v1.5_official_release/uavid_val/**/Images/*.png\"\n",
    "        images = glob.glob(directory, recursive=True)\n",
    "        directory = \"/home/hackerton/Downloads/uavid_v1.5_official_release/uavid_val/**/Labels/*.png\"\n",
    "        labels = glob.glob(directory, recursive=True)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.cache()\n",
    "    if istrain:\n",
    "        ds = ds.shuffle(6400, SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(get_image_decode, AUTOTUNE)\n",
    "\n",
    "    if not maximage:\n",
    "        ds = ds.flat_map(decode_crop)\n",
    "\n",
    "    ds = ds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # batch and prefetch\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    if istrain:\n",
    "        ds = ds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ef5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=False)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "        m_all = self.final_activation(m_all)\n",
    "\n",
    "        return m_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebebd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_ORIG(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN_ORIG\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=(n_classes), kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale2x_1 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_2 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_3 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.upscale2x_4 = tf.keras.layers.Convolution2DTranspose(\n",
    "            filters=8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=(4, 4),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.final_activation = tf.keras.layers.Activation(\"softmax\")\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv1_o, conv2_o, conv3_o, conv4_o = self.backbone(images, training=False)\n",
    "        conv1_o = self.conv1(conv1_o)\n",
    "        conv2_o = self.conv2(conv2_o)\n",
    "        conv3_o = self.conv3(conv3_o)\n",
    "\n",
    "        fcn_16x = self.upscale2x_1(conv4_o) + conv3_o\n",
    "        fcn_8x = self.upscale2x_2(fcn_16x) + conv2_o\n",
    "        fcn_4x = self.upscale2x_3(fcn_8x) + conv1_o\n",
    "        final_output = self.upscale2x_4(fcn_4x)\n",
    "        final_output = self.final_activation(final_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6385667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network must OUTPUT in logits [-inf, inf]\n",
    "# make sure input dimension is [B, H, W, C]\n",
    "def Jindex(target, pred):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "\n",
    "def Dice(target, pred):\n",
    "    intersection = tf.reduce_sum(2 * pred * target, [0, 1, 2])\n",
    "    union = tf.reduce_sum(pred + target, [0, 1, 2])\n",
    "    return tf.reduce_mean((intersection + 0.1) / (union + 0.1))\n",
    "\n",
    "def Jindex_class(target, pred):\n",
    "    intersection = tf.reduce_sum(target * pred, [0, 1, 2])\n",
    "    union = tf.reduce_sum(target + pred, [0, 1, 2]) - intersection\n",
    "    return (intersection + 0.1) / (union + 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d00152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# lr = 0.001 is good but spiky, next learning rate to test is 0.0005\n",
    "# both fpn and unet uses 1e-4 learning rate\n",
    "\n",
    "# test_fpn, lr = 0.00001 (1e-4)\n",
    "# lr=1e-6, slow\n",
    "# lr=1e-5, fast\n",
    "# lr=5e-5, can trained but stagnate at 12k with iou of 0.69\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e43513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 03:02:52.596544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:52.626704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:52.627136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:52.628117: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-03 03:02:52.628928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:52.629452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:52.630029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:53.219589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:53.219886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:53.220123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 03:02:53.220282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1621 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trained_model/unet/ckpt-20'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this iteration is calculated fom 160 iteration from\n",
    "# paper\n",
    "\n",
    "model_selection = [\"fcn8s\", \"unet\", \"fpn\"]\n",
    "model_choice = 1\n",
    "name_model = model_selection[model_choice]\n",
    "\n",
    "n_classes = 8\n",
    "batch_size = 8\n",
    "trainds = create_ds(batch_size)\n",
    "testds = create_ds(batch_size, False)\n",
    "\n",
    "if model_choice == 0:\n",
    "    model = FCN_ORIG(n_classes)\n",
    "elif model_choice == 1:\n",
    "    model = sm.Unet(\n",
    "        backbone_name=\"efficientnetb0\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        encoder_freeze=False,\n",
    "        activation=\"softmax\",\n",
    "        classes=n_classes,\n",
    "        decoder_use_batchnorm=False,\n",
    "    )\n",
    "elif model_choice == 2:\n",
    "    model = FCN(8)\n",
    "else:\n",
    "    assert \"No model chosen\"\n",
    "\n",
    "\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model/{name_model}\", 5)\n",
    "ckptmg.restore_or_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d66a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 03:02:59.286732: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-03 03:03:03.078701: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-06-03 03:03:03.469200: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-06-03 03:03:03.544150: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14415/3427363991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_choice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbs_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"efficientnetb0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mjindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJindex_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0miou_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    452\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/keras/layers/core/activation.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/efficientnet/model.py\u001b[0m in \u001b[0;36mswish\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m  \u001b[0mswish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    532\u001b[0m   \"\"\"\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf21/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6575\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6576\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6577\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[1;32m   6578\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ALPHA = 1.0\n",
    "\n",
    "# testing on train dataset and testing dataset\n",
    "iou_train = np.zeros([800, 8])\n",
    "iou_test = np.zeros([280, 8])\n",
    "\n",
    "# training set\n",
    "print('Training set...')\n",
    "time_init = time.time()\n",
    "for idx, (bs_images, bs_labels) in trainds.enumerate():\n",
    "    if model_choice == 1:\n",
    "        bs_images = sm.get_preprocessing(\"efficientnetb0\")(bs_images)\n",
    "    output = model(bs_images, training=False)\n",
    "    jindex = Jindex_class(bs_labels, output)\n",
    "    iou_train[idx] = jindex\n",
    "time_taken = time.time() - time_init\n",
    "print(f'Time taken: {round(time_taken, 3)}s')\n",
    "print(f'IoU: {round(np.average(iou_train), 3)}')\n",
    "\n",
    "# testing set\n",
    "print('Testing set...')\n",
    "time_init = time.time()\n",
    "for idx, (bs_images, bs_labels) in testds.enumerate():\n",
    "    if model_choice == 1:\n",
    "        bs_images = sm.get_preprocessing(\"efficientnetb0\")(bs_images)\n",
    "    output = model(bs_images, training=False)\n",
    "    jindex = Jindex_class(bs_labels, output)\n",
    "    iou_test[idx] = jindex\n",
    "time_taken = time.time() - time_init\n",
    "print(f'Time taken: {round(time_taken, 3)}s')\n",
    "print(f'IoU: {round(np.average(iou_test), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1 artists>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=['train'], height=[np.average(iou_train)], color='blue', align='center')\n",
    "plt.bar(x=['test'], height=[np.average(iou_test)], color='red', align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5c9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f98fe3d7880>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(\n",
    "    x=[x + 1 for x in range(8)],\n",
    "    height=np.average(iou_train, 0),\n",
    "    color=\"blue\",\n",
    "    width=-0.4,\n",
    "    align=\"edge\",\n",
    "    label='train'\n",
    "\n",
    ")\n",
    "\n",
    "plt.bar(\n",
    "    x=[x + 1 for x in range(8)],\n",
    "    height=np.average(iou_test, 0),\n",
    "    color=\"red\",\n",
    "    width=0.4,\n",
    "    align=\"edge\",\n",
    "    label='test'\n",
    ")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728120dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "  return np.concatenate([[x[0]], x[1], x[2]])\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    list(map(convert, [[name_model, np.average(iou_train, 0), np.average(iou_test, 0)]])),\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"trainc1\",\n",
    "        \"trainc2\",\n",
    "        \"trainc3\",\n",
    "        \"trainc4\",\n",
    "        \"trainc5\",\n",
    "        \"trainc6\",\n",
    "        \"trainc7\",\n",
    "        \"trainc8\",\n",
    "        \"testc1\",\n",
    "        \"testc2\",\n",
    "        \"testc3\",\n",
    "        \"testc4\",\n",
    "        \"testc5\",\n",
    "        \"testc6\",\n",
    "        \"testc7\",\n",
    "        \"testc8\",\n",
    "    ],\n",
    ")\n",
    "second = results.pop('model')\n",
    "\n",
    "results.iloc[:, 0:] = results.iloc[:, 0:].astype('float')\n",
    "results['model'] = second\n",
    "results.to_csv(f'results_{name_model}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0beed873570eadf18b27de988f74387134654fe26ad0c1ed6b53170102862c4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tf21')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

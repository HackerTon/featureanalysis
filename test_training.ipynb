{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import ResNet50_Weights, resnet50\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.transforms import RandomCrop, Resize, transforms\n",
    "from torchvision.transforms.functional import crop\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class UAVIDDataset4K(Dataset):\n",
    "    def __init__(self, path, is_train=True):\n",
    "        directory = Path(path)\n",
    "        if is_train:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_train/**/Images/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_train/**/Labels/*.png\")\n",
    "            ]\n",
    "        else:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_val/**/Images/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_val/**/Labels/*.png\")\n",
    "            ]\n",
    "\n",
    "        if len(self.images) is not len(self.labels):\n",
    "            print(\"Number of images & label are not the same.\")\n",
    "            return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_image(image_path):\n",
    "        return read_image(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_image(image):\n",
    "        resizer = Resize([2160, 3840], antialias=\"True\")\n",
    "        return resizer(image)\n",
    "\n",
    "    @staticmethod\n",
    "    def label_0and1(label):\n",
    "        return label.type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def image_0and1(image):\n",
    "        return (image / 255).type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_label(label):\n",
    "        labels = []\n",
    "        labels.append((label[0] == 0) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 64) & (label[2] == 128))\n",
    "        labels.append((label[0] == 0) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 64) & (label[1] == 0) & (label[2] == 128))\n",
    "        labels.append((label[0] == 192) & (label[1] == 0) & (label[2] == 192))\n",
    "        labels.append((label[0] == 64) & (label[1] == 64) & (label[2] == 0))\n",
    "        return torch.stack(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.decode_image(self.images[index])\n",
    "        image = self.resize_image(image)\n",
    "        image = self.image_0and1(image)\n",
    "\n",
    "        label = self.decode_image(self.labels[index])\n",
    "        label = self.resize_image(label)\n",
    "        label = self.label_0and1(label)\n",
    "        label = self.mask_label(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class UAVIDDataset(Dataset):\n",
    "    def __init__(self, path, is_train=True):\n",
    "        directory = Path(path)\n",
    "        if is_train:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"train/image/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"train/label/*.png\")\n",
    "            ]\n",
    "        else:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"test/image/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"test/label/*.png\")\n",
    "            ]\n",
    "\n",
    "        if len(self.images) != len(self.labels):\n",
    "            print(\"Number of images & label are not the same.\")\n",
    "            return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_image(image_path):\n",
    "        return read_image(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_image(image):\n",
    "        resizer = Resize([2160, 3840], antialias=\"True\")\n",
    "        return resizer(image)\n",
    "\n",
    "    @staticmethod\n",
    "    def label_0and1(label):\n",
    "        return label.type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def image_0and1(image):\n",
    "        return (image / 255).type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_label(label):\n",
    "        labels = []\n",
    "        labels.append((label[0] == 0) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 64) & (label[2] == 128))\n",
    "        labels.append((label[0] == 0) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 64) & (label[1] == 0) & (label[2] == 128))\n",
    "        labels.append((label[0] == 192) & (label[1] == 0) & (label[2] == 192))\n",
    "        labels.append((label[0] == 64) & (label[1] == 64) & (label[2] == 0))\n",
    "        return torch.stack(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.decode_image(self.images[index])\n",
    "        i, j, h, w = RandomCrop.get_params(image, (256, 256))\n",
    "        image = self.image_0and1(image)\n",
    "        label = self.decode_image(self.labels[index])\n",
    "        label = self.mask_label(label)\n",
    "        label = self.label_0and1(label)\n",
    "\n",
    "        # Crop image and label\n",
    "        image = crop(image, i, j, h, w)\n",
    "        label = crop(label, i, j, h, w)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset_labels = [\n",
    "    \"background\",\n",
    "    \"building\",\n",
    "    \"road\",\n",
    "    \"tree\",\n",
    "    \"vegetation\",\n",
    "    \"moving_car\",\n",
    "    \"stationary_car\",\n",
    "    \"human\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# training_data = UAVIDDataset4K(path=\"data/uavid_v1.5_official_release_image\", is_train=True)\n",
    "training_data = UAVIDDataset(path=\"/Users/babi/Programs/high_performance_analysis_system/data/processed_dataset/\", is_train=True)\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "train_feature, train_label = next(iter(train_dataloader))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(torch.permute(train_feature[0], [1, 2, 0]))\n",
    "\n",
    "figure, axes = plt.subplots(8, 1, figsize=(16, 32))\n",
    "for i in range(8):\n",
    "    axes[i].set_axis_off()\n",
    "    axes[i].imshow(\n",
    "        torch.permute(train_label, [0, 2, 3, 1]).numpy()[0, ..., i],\n",
    "        cmap=\"gray\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    axes[i].text(5, 5, dataset_labels[i], bbox={'facecolor': 'white', 'pad': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class UNETNetwork(nn.Module):\n",
    "    def __init__(self, numberClass):\n",
    "        super().__init__()\n",
    "        _resnet50 = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.backbone = create_feature_extractor(\n",
    "            _resnet50,\n",
    "            {\n",
    "                \"relu\": \"feat1\",\n",
    "                \"layer1\": \"feat2\",\n",
    "                \"layer2\": \"feat3\",\n",
    "                \"layer3\": \"feat4\",\n",
    "                \"layer4\": \"feat5\",\n",
    "            },\n",
    "        )\n",
    "        self.upsampling_2x = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.upsampling_2x_bilinear = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=2048, out_channels=1024, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=1024, out_channels=512, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=512, out_channels=256, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=256, out_channels=128, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.convfinal = nn.Conv2d(\n",
    "            in_channels=128, out_channels=numberClass, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        backbone_output = self.backbone(x)\n",
    "        feat2, feat3, feat4, feat5 = (\n",
    "            backbone_output[\"feat2\"],\n",
    "            backbone_output[\"feat3\"],\n",
    "            backbone_output[\"feat4\"],\n",
    "            backbone_output[\"feat5\"],\n",
    "        )\n",
    "        feat4to6 = self.upsampling_2x_bilinear(self.conv5(feat5).relu())\n",
    "        feat3to7 = self.upsampling_2x_bilinear(self.conv6(feat4 + feat4to6).relu())\n",
    "        feat2to8 = self.upsampling_2x_bilinear(self.conv7(feat3 + feat3to7).relu())\n",
    "        featout = self.upsampling_2x_bilinear(self.conv8(feat2 + feat2to8).relu())\n",
    "        return self.upsampling_2x_bilinear(self.convfinal(featout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def dice_loss(\n",
    "    pred: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    epsilon=1e-9,\n",
    "):\n",
    "    pred_flat = pred.flatten()\n",
    "    target_flat = target.flatten()\n",
    "    nominator = 2 * torch.matmul(pred_flat, target_flat)\n",
    "    denominator = torch.sum(pred_flat) + torch.sum(target_flat)\n",
    "    return 1 - ((nominator + epsilon) / (denominator + epsilon))\n",
    "\n",
    "\n",
    "def total_loss(pred: torch.Tensor, target: torch.Tensor):\n",
    "    return torch.nn.functional.cross_entropy(\n",
    "        pred,\n",
    "        target,\n",
    "    ) + dice_loss(\n",
    "        pred.softmax(1),\n",
    "        target,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "training_data = UAVIDDataset(\n",
    "    path=\"/Users/babi/Programs/high_performance_analysis_system/data/processed_dataset/\",\n",
    "    is_train=True,\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "model = UNETNetwork(numberClass=8).to(\"mps\")\n",
    "optimizer_sgd = torch.optim.SGD(params=model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]).to(\"mps\")\n",
    "timestamp = datetime.datetime.now().strftime(r\"%Y%m%d_%H%M%S\")\n",
    "writer = SummaryWriter(\"data/training/train_{}\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    model.train(True)\n",
    "    running_loss = 0.0\n",
    "    for idx, data in enumerate(tqdm(train_dataloader)):\n",
    "        inputs: torch.Tensor\n",
    "        labels: torch.Tensor\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_sgd.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(\"mps\")\n",
    "        labels = labels.to(\"mps\")\n",
    "\n",
    "        inputs = normalize(inputs)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = total_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_sgd.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if idx % 500 == 499:\n",
    "            current_training_sample = epoch * len(train_dataloader) + idx + 1\n",
    "            writer.add_scalar(\"Loss/train\", running_loss / 500, current_training_sample)\n",
    "            print(f\"Loss: {running_loss / 500}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = np.zeros([256, 256, 3], dtype=np.uint8)\n",
    "output_image2 = np.zeros_like(output_image, dtype=np.uint8)\n",
    "model.eval()\n",
    "colors = np.array(\n",
    "    [\n",
    "        [0, 0, 0],\n",
    "        [128, 0, 0],\n",
    "        [128, 64, 128],\n",
    "        [0, 128, 0],\n",
    "        [128, 128, 0],\n",
    "        [64, 0, 128],\n",
    "        [192, 0, 192],\n",
    "        [64, 64, 0],\n",
    "    ],\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "test_data = UAVIDDataset(path=\"/Users/babi/Programs/high_performance_analysis_system/data/processed_dataset/\", is_train=False)\n",
    "test_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "test_feature, test_label = next(iter(test_dataloader))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 9))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(normalize(test_feature.to('mps')))\n",
    "    outputs = outputs.to(\"cpu\").softmax(axis=1)\n",
    "    for i in range(8):\n",
    "        mask = test_label[0, i] == 1\n",
    "        output_image[mask] = colors[i]\n",
    "\n",
    "        mask2 = outputs[0, i] > 0.5\n",
    "        output_image2[mask2] = colors[i]\n",
    "\n",
    "    axes[0].set_axis_off()\n",
    "    axes[1].set_axis_off()\n",
    "    axes[2].set_axis_off()\n",
    "    axes[0].imshow(torch.permute(test_feature, [0, 2, 3, 1])[0])\n",
    "    axes[1].imshow(output_image)\n",
    "    axes[2].imshow(output_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models as sm\n",
    "import functools as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "import os\n",
    "\n",
    "sm.set_framework(\"tf.keras\")\n",
    "sm.framework()\n",
    "\n",
    "tf.random.set_seed(1024)\n",
    "SEED = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2dae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seagull_path(istrain=True):\n",
    "    directory = \"/home/hackerton/Downloads/seagull\"\n",
    "\n",
    "    if istrain:\n",
    "        trainimg = os.path.join(directory, \"trainimg\", \"*.jpg\")\n",
    "        images = glob.glob(trainimg, recursive=True)\n",
    "        trainmask = os.path.join(directory, \"trainmask\", \"*.jpg\")\n",
    "        labels = glob.glob(trainmask, recursive=True)\n",
    "    else:\n",
    "        testimg = os.path.join(directory, \"testimg\", \"*.jpg\")\n",
    "        images = glob.glob(testimg, recursive=True)\n",
    "        testmask = os.path.join(directory, \"testmask\", \"*.jpg\")\n",
    "        labels = glob.glob(testmask, recursive=True)\n",
    "\n",
    "    print(len(images), len(labels))\n",
    "\n",
    "    mask_set = set()\n",
    "    image_set = set()\n",
    "    for lbl in labels:\n",
    "        lbl = lbl.split('/')[-1]\n",
    "        mask_set.add(lbl)\n",
    "\n",
    "    for img in images:\n",
    "        img = img.split('/')[-1]\n",
    "        image_set.add(img)\n",
    "\n",
    "    complete_path = mask_set.intersection(image_set)\n",
    "    print(\n",
    "        f\"IMG - LBL NUM: {len(image_set.difference(mask_set))}, Intersection: {len(complete_path)}\"\n",
    "    )\n",
    "\n",
    "    return [i for i in complete_path]\n",
    "\n",
    "def get_image_decode(image, label):\n",
    "    image = tf.io.read_file(image, \"image\")\n",
    "    label = tf.io.read_file(label, \"label\")\n",
    "\n",
    "    image = tf.image.decode_image(image)\n",
    "    label = tf.image.decode_image(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def path_2_test(path):\n",
    "    return (\n",
    "        r\"/home/hackerton/Downloads/seagull/testimg/\" + path,\n",
    "        r\"/home/hackerton/Downloads/seagull/testmask/\" + path,\n",
    "    )\n",
    "\n",
    "\n",
    "def path_2_train(path):\n",
    "    return (\n",
    "        r\"/home/hackerton/Downloads/seagull/testimg/\" + path,\n",
    "        r\"/home/hackerton/Downloads/seagull/testmask/\" + path,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_mask(image, label):\n",
    "    labels = []\n",
    "    labels.append(label[:, :, 0] == 0)\n",
    "    labels.append(label[:, :, 0] == 255)\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # must perform this\n",
    "    return image, tf.transpose(labels, [1, 2, 0])\n",
    "\n",
    "\n",
    "def create_ds(batch_size, ratio=0.8):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    paths = get_seagull_path()\n",
    "    ds1 = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds1 = ds1.map(path_2_train, AUTOTUNE)\n",
    "\n",
    "    paths = get_seagull_path(False)\n",
    "    ds2 = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds2 = ds2.map(path_2_test, AUTOTUNE)\n",
    "\n",
    "    ds = ds1.concatenate(ds2)\n",
    "    ds = ds.cache()\n",
    "\n",
    "    takefortrain = int(23124 * ratio)\n",
    "    trainds = ds.take(takefortrain)\n",
    "    testds = ds.skip(takefortrain).take(23124 - takefortrain)\n",
    "\n",
    "    trainds = trainds.shuffle(23124)\n",
    "\n",
    "    trainds = trainds.map(get_image_decode, AUTOTUNE)\n",
    "    trainds = trainds.map(get_mask, AUTOTUNE)\n",
    "    testds = testds.map(get_image_decode, AUTOTUNE)\n",
    "    testds = testds.map(get_mask, AUTOTUNE)\n",
    "\n",
    "    # # batch and prefetch\n",
    "    trainds = trainds.batch(batch_size)\n",
    "    testds = testds.batch(batch_size)\n",
    "\n",
    "    trainds = trainds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return trainds, testds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone_efficient():\n",
    "    _backbone = keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "    outputs = [\n",
    "        layer.output\n",
    "        for layer in _backbone.layers\n",
    "        if layer.name\n",
    "        in [\n",
    "            \"block2a_activation\",\n",
    "            \"block3a_activation\",\n",
    "            \"block5a_activation\",\n",
    "            \"block7a_activation\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[_backbone.input], outputs=outputs, name=\"efficientb0_backbone\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(tf.keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"Feature_Pyramid_Network\", **kwargs)\n",
    "\n",
    "        self.backbone = create_backbone_efficient()\n",
    "\n",
    "        self.conv5_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv4_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv3_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv2_1x1 = tf.keras.layers.Conv2D(\n",
    "            filters=256, kernel_size=(1, 1), padding=\"same\"\n",
    "        )\n",
    "        self.conv5_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv5_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_1 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2_3x3_2 = tf.keras.layers.Conv2D(\n",
    "            filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        # 112x112, 56x56, 28x28, 14x14\n",
    "        conv2, conv3, conv4, conv5 = self.backbone(images, training=False)\n",
    "        conv5_m = self.conv5_1x1(conv5)\n",
    "        conv5_p = self.conv5_3x3_1(conv5_m)\n",
    "        conv5_p = self.conv5_3x3_2(conv5_p)\n",
    "\n",
    "        conv4_m_1 = self.upscale(conv5_m)\n",
    "        conv4_m_2 = self.conv4_1x1(conv4)\n",
    "        conv4_m = conv4_m_1 + conv4_m_2\n",
    "        conv4_p = self.conv4_3x3_1(conv4_m)\n",
    "        conv4_p = self.conv4_3x3_2(conv4_p)\n",
    "\n",
    "        conv3_m_1 = self.upscale(conv4_m)\n",
    "        conv3_m_2 = self.conv3_1x1(conv3)\n",
    "        conv3_m = conv3_m_1 + conv3_m_2\n",
    "        conv3_p = self.conv3_3x3_1(conv3_m)\n",
    "        conv3_p = self.conv3_3x3_2(conv3_p)\n",
    "\n",
    "        conv2_m_1 = self.upscale(conv3_m)\n",
    "        conv2_m_2 = self.conv2_1x1(conv2)\n",
    "        conv2_m = conv2_m_1 + conv2_m_2\n",
    "        conv2_p = self.conv2_3x3_1(conv2_m)\n",
    "        conv2_p = self.conv2_3x3_2(conv2_p)\n",
    "\n",
    "        return conv5_p, conv4_p, conv3_p, conv2_p\n",
    "\n",
    "\n",
    "class FCN(tf.keras.Model):\n",
    "    def __init__(self, n_classes=8, backbone=None, **kwargs):\n",
    "        super().__init__(name=\"FCN\", **kwargs)\n",
    "        self.fpn = FPN(backbone)\n",
    "        self.upscale_2x = tf.keras.layers.UpSampling2D()\n",
    "        self.upscale_4x = tf.keras.layers.UpSampling2D((4, 4))\n",
    "        self.upscale_8x = tf.keras.layers.UpSampling2D((8, 8))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.conv6 = tf.keras.layers.Conv2D(\n",
    "            filters=(512), kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv7 = tf.keras.layers.Conv2D(\n",
    "            filters=n_classes, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.upscale_final = tf.keras.layers.UpSampling2D(\n",
    "            size=(4, 4), interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        conv5_p, conv4_p, conv3_p, conv2_p = self.fpn(images, training=training)\n",
    "        m_5 = self.upscale_8x(conv5_p)\n",
    "        m_4 = self.upscale_4x(conv4_p)\n",
    "        m_3 = self.upscale_2x(conv3_p)\n",
    "        m_2 = conv2_p\n",
    "\n",
    "        m_all = self.concat([m_2, m_3, m_4, m_5])\n",
    "        m_all = self.conv6(m_all)\n",
    "        m_all = self.conv7(m_all)\n",
    "        m_all = self.upscale_final(m_all)\n",
    "\n",
    "        return m_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescalingUnet(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(RescalingUnet, self).__init__()\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return ((inputs * (1 / 255.0)) - self.mean) / self.std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de64f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model(mode=\"multi\", n_classes=8):\n",
    "    model_unet = sm.Unet(\n",
    "        backbone_name=\"efficientnetb0\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        encoder_freeze=False,\n",
    "        classes=n_classes,\n",
    "        decoder_use_batchnorm=False,\n",
    "        activation='linear'\n",
    "    )\n",
    "    model_fpn = FCN(n_classes)\n",
    "\n",
    "    conv1x1 = keras.layers.Conv2D(n_classes, 1, padding=\"same\", activation=\"softmax\")\n",
    "    rescale_layer = RescalingUnet()\n",
    "    input_layer = keras.layers.Input([None, None, 3])\n",
    "\n",
    "    output_model_fcn = model_unet(rescale_layer(input_layer))\n",
    "    output_model_fpn = model_fpn(input_layer)\n",
    "    output = output_model_fcn *output_model_fpn\n",
    "    output_final = conv1x1(output)\n",
    "\n",
    "    return keras.Model([input_layer], [output_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this iteration is calculated fom 160 iteration from\n",
    "# paper\n",
    "n_epoch = 35\n",
    "n_classes = 2\n",
    "batch_size = 8\n",
    "trainds, testds = create_ds(batch_size)\n",
    "\n",
    "model = combined_model(n_classes=n_classes)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(1e-5)\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckptmg = tf.train.CheckpointManager(ckpt, f\"trained_model_seagull/unetfpn\", 5)\n",
    "ckptmg.restore_or_initialize()\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = f\"logs_seagull/unetfpn/{current_time}/train\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_log_dir = f\"logs_seagull/unetfpn/{current_time}/test\"\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d66a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real training\n",
    "train_iteration = 0\n",
    "iteration = 0\n",
    "\n",
    "sum_iou = 0\n",
    "sum_loss = 0\n",
    "ALPHA = 1.0\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    initial_time = time.time()\n",
    "    for bs_images, bs_labels in trainds:\n",
    "        with tf.GradientTape() as t:\n",
    "            output = model(bs_images, training=True)\n",
    "            c_loss = dice_loss(bs_labels, output)\n",
    "            c_loss += ALPHA * focal_loss(bs_labels, output)\n",
    "\n",
    "        grad = t.gradient(c_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "        sum_loss = c_loss\n",
    "        train_iteration += 1\n",
    "\n",
    "        # calculate loss and IoU at iteration\n",
    "        # this is train\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar(\"loss\", c_loss, step=train_iteration)\n",
    "            tf.summary.scalar(\n",
    "                \"iou\", sm.metrics.iou_score(bs_labels, output), step=train_iteration\n",
    "            )\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Time Taken: {round(time.time() - initial_time, 3)}s\")\n",
    "\n",
    "    for bs_images, bs_labels in testds:\n",
    "        output = model(bs_images, training=False)\n",
    "        sum_loss += (\n",
    "            dice_loss(bs_labels, output) + ALPHA * focal_loss(bs_labels, output)\n",
    "        ) * batch_size\n",
    "        sum_iou += sm.metrics.iou_score(bs_labels, output) * batch_size\n",
    "        iteration += batch_size\n",
    "\n",
    "    # calculate validation loss and IoU\n",
    "    # this is test\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar(\"loss\", sum_loss / iteration, step=train_iteration)\n",
    "        tf.summary.scalar(\"iou\", sum_iou / iteration, step=train_iteration)\n",
    "\n",
    "    iteration = 0\n",
    "    sum_iou = 0\n",
    "    sum_loss = 0\n",
    "    ckptmg.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f009644687fbff803937e34e13187dc56579602643eee9f001c34fd1c6bb4d9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
